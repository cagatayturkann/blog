{
    "title": "Modern AI Teknolojileri ve Node.js Entegrasyonu",
    "permalink": "/blog/tr/modern-ai-teknolojileri-nodejs-entegrasyonu/",
    "summary": "Bu makalede, yapay zeka teknolojilerinin JavaScript ekosistemindeki uygulamalarını inceleyeceğiz. AI agent\u0026rsquo;lar, tool calling, conversation memory, context yönetimi gibi temel kavramların Node.js uygulamalarında nasıl hayata geçirileceğini örnek projeler üzerinden ele alacağız.",
    "content": "Modern AI Teknolojileri ve Node.js Entegrasyonu Giriş Yapay zeka teknolojileri, özellikle dil modelleri, yazılım geliştirme dünyasını hızla dönüştürüyor. Node.js gibi popüler bir platform ile AI teknolojilerini entegre etmek, JavaScript ekosisteminde çalışan geliştiricilere inanılmaz fırsatlar sunuyor. Bu makalede, modern AI konseptlerini Node.js çerçevesinde nasıl uygulayabileceğimizi inceleyeceğiz.\nBu yazı size şunları kazandıracak:\nAI terminolojisini ve temel kavramlarını anlama Node.js ile LLM (Large Language Model) entegrasyonu AI agent\u0026rsquo;lar oluşturma ve araç çağırma (tool calling) yeteneğini anlama Açık kaynak AI teknolojilerini (Ollama, LiteLLM, LlamaCPP) Node.js uygulamalarında kullanma Otomatik iş akışları için N8n ile AI entegrasyonu Projelerin tam kodlarına GitHub repository adresinden erişebilirsiniz.\n1. AI Agent\u0026rsquo;lar: Akıllı Asistanlar Geliştirme AI Agent Nedir? AI agent, LLM\u0026rsquo;leri (Large Language Models) kullanarak belirli görevleri gerçekleştirmek üzere tasarlanmış yazılım sistemleridir. Bu ajanlar, insan benzeri düşünme, karar verme ve çevresiyle etkileşim kurma yeteneklerine sahiptir. AI agent\u0026rsquo;ı, belirli görevleri yerine getirmek üzere tasarlanmış otonom bir yazılım bileşenidir. Bu agentlar:\nVeri alır (input): Örneğin, kullanıcıdan gelen sorgular veya sistemden gelen veriler. İşlem yapar (processing): Bu veriler üzerinde analiz yapar, karar verir veya model çalıştırır. Çıktı verir (output): Sonuçları veya eylemleri gerçekleştirir. Modern AI agent\u0026rsquo;lar tipik olarak şu bileşenleri içerir:\nLLM (Beyin): Doğal dil anlama ve üretme yeteneği Bellek (Memory): Geçmiş etkileşimleri hatırlama Araçlar (Tools): API\u0026rsquo;ler, veritabanları ve diğer sistemlerle etkileşime geçme yeteneği Planlama: Karmaşık görevleri alt görevlere bölebilme AI Agent\u0026rsquo;lar reaktif yani herhangi bir kullanıcı tetikleyicisi olmadan kendi başına veri toplama, çevri analizi vs işlemler yapmayan basit agentlar olabileceği gibi daha yaygın olarak otonom da olabilir. Otonom bir agent; örneğin, bir akıllı ev sisteminde olduğu gibi, ortamı sürekli izleyebilir, belirli durumları algılayıp kendi kararlarını verebilir. Bu tarz bir agent; sürekli sensör vb kaynaklardan veri toplar, bu verileri analiz eder ve bu analize göre kendi başına belirli görevler başlatır veya ayarlar.\nNode.js ile AI Agent Oluşturma Node.js ve OpenAI API kullanarak basit bir otonom agent örneği yapalım. Bu örnekte, ajan belirli aralıklarla \u0026ldquo;sensör verisi\u0026rdquo; üretip, bu veriye göre OpenAI\u0026rsquo;dan aldığı karara göre hareket ediyor. Öncelikle gerekli paketi indiriyoruz.\nnpm install openai Daha sonra ise kodumuz aşağıdaki şekilde.\nconst { OpenAI } = require(\u0026#39;openai\u0026#39;); // OpenAI yapılandırması: API anahtarınızı buraya ekleyin. const openai = new OpenAI({ apiKey: \u0026#39;your-api-key\u0026#39;, }); // Otonom ajan fonksiyonu async function autonomousAgent() { console.log(\u0026#39;Ajan çalışmaya başladı...\u0026#39;); // 1. Adım: Sensör verisini simüle et (örneğin, rastgele bir sayı) const sensorData = Math.random() * 100; console.log(\u0026#39;Sensör verisi:\u0026#39;, sensorData); // 2. Adım: Sensör verisine dayalı karar vermek için OpenAI\u0026#39;ya prompt gönder const prompt = `Sensör verisi: ${sensorData}. Eğer veri 50\u0026#39;den büyükse \u0026#34;Alarm\u0026#34;, 50 veya daha düşükse \u0026#34;Normal\u0026#34; sonucunu tek kelime olarak ver.`; try { const response = await openai.chat.completions.create({ model: \u0026#39;gpt-4o-mini\u0026#39;, messages: [{ role: \u0026#39;user\u0026#39;, content: prompt }], max_tokens: 10, temperature: 0.3, }); const decision = response.choices[0].message.content.trim(); console.log(\u0026#39;Ajan Kararı:\u0026#39;, decision); // 3. Adım: OpenAI\u0026#39;dan gelen karara göre hareket et if (decision === \u0026#39;Alarm\u0026#39;) { console.log(\u0026#39;Alarm durumu tespit edildi, gerekli işlemleri başlatıyor...\u0026#39;); // Burada alarmı tetiklemek veya bildirim göndermek gibi işlemler yapılabilir. } else if (decision === \u0026#39;Normal\u0026#39;) { console.log(\u0026#39;Durum normal, bekleme modunda...\u0026#39;); // Normal durumda yapılacak başka işlemler eklenebilir. } else { console.log(\u0026#39;Bilinmeyen karar, tekrar kontrol ediliyor...\u0026#39;); // Beklenmeyen durumlarda hata yönetimi yapılabilir. } } catch (error) { console.error(\u0026#39;Hata oluştu:\u0026#39;, error); } } // Ajanı her 30 saniyede bir otomatik olarak çalıştır. setInterval(autonomousAgent, 10000); // Program başladığında hemen bir kere çalıştır. autonomousAgent(); Bu kod parçasını daha detaylı açıklayacak olursak\nSensör Verisi Üretimi: Agent, her çalıştığında rastgele bir sayı üretiyor. Bu sayı, örnek bir sensör verisi olarak düşünülüyor. Karar Süreci: Üretilen sensör verisi, bir prompt içerisinde OpenAI API\u0026rsquo;ya gönderiliyor. Bu prompt, veriye göre \u0026ldquo;Alarm\u0026rdquo; veya \u0026ldquo;Normal\u0026rdquo; kelimesi döndürmesini istiyor. Eylem: OpenAI\u0026rsquo;dan gelen yanıt, agentın kararını belirliyor. Eğer yanıt \u0026ldquo;Alarm\u0026rdquo; ise, agent alarm durumunu tetikleyen işlemleri gerçekleştiriyor; \u0026ldquo;Normal\u0026rdquo; ise, bekleme modunda kalıyor. Otonomluk: Agent, kullanıcı müdahalesi olmadan belirli aralıklarla (burada her 30 saniyede bir) kendi başına çalışarak, sensör verisini değerlendiriyor ve otomatik olarak karar veriyor. Bu örnek, otonom agent kavramını, sadece kullanıcı girdisine bağlı olmayan, kendi kendini tetikleyen ve belirli şartlara göre karar veren bir yapı olarak göstermektedir. Böylece, sistem belirli bir zaman döngüsünde bağımsız çalışarak çevresel veriye göre eylem alabiliyor.\nAI Agent Çalışma Prensibi AI agent\u0026rsquo;lar genellikle şu adımları izler:\nDüşünme: İstenen görev için bir plan oluşturma Aracı Seçme: Görevi tamamlamak için hangi aracı kullanacağına karar verme Eylem: Seçilen aracı kullanarak belirli bir eylemi gerçekleştirme Gözlemleme: Eylemin sonucunu inceleme İlerleme: Sonuca göre yeni bir düşünme-eylem döngüsü başlatma Bu yaklaşım ReAct (Reasoning and Acting) olarak bilinir ve LLM\u0026rsquo;in düşünmeyle eylemi birleştirmesini sağlar.\nNeden Bu Özellik Önemli? Otomatikleştirilebilir işlemleri akıllı asistanlara devredebilirsiniz İnsan kullanıcılara daha doğal bir arayüz sunabilirsiniz Karmaşık iş akışlarını modüler araçlarla basitleştirebilirsiniz 2. Embedding, RAG, VectorDB Embedding Embedding, metin veya diğer veri türlerini sayısal vektörlere dönüştürme işlemidir. Bu vektörler, verinin anlamsal özelliklerini sayısal formatta temsil eder. Örneğin, \u0026ldquo;köpek\u0026rdquo; ve \u0026ldquo;kedi\u0026rdquo; kelimeleri birbirine yakın vektörlerle temsil edilirken, \u0026ldquo;araba\u0026rdquo; daha uzak bir vektörle temsil edilir.\nEmbeddingler şu amaçlarla kullanılır:\nMetin benzerliği hesaplama Doküman sınıflandırma Semantik arama Öneriler oluşturma Duygu analizi Metin özetleme Doğal dil işleme görevleri Embedding\u0026rsquo;lerin çalışma prensibi şu şekildedir:\nTokenization: Metin önce daha küçük parçalara (token) ayrılır Vektör Dönüşümü: Her token, yüzlerce veya binlerce boyutlu bir vektöre dönüştürülür Normalizasyon: Vektörler normalize edilerek karşılaştırılabilir hale getirilir Embedding\u0026rsquo;lerin en önemli özelliği, benzer anlamlara sahip içeriklerin vektör uzayında birbirine yakın konumlanmasıdır. Bu sayede, metin tabanlı aramalarda kelime eşleştirmeden ziyade anlam bazlı sonuçlar elde edilebilir. Örneğin, \u0026ldquo;mutlu\u0026rdquo; ve \u0026ldquo;sevinçli\u0026rdquo; kelimeleri vektör uzayında birbirine yakın konumlanırken, \u0026ldquo;üzgün\u0026rdquo; kelimesi uzak bir noktada yer alır.\nRAG (Retrieval Augmented Generation) RAG, büyük dil modellerinin (LLM) mevcut bilgi tabanını harici kaynaklarla zenginleştiren bir tekniktir. RAG sistemi şu şekilde çalışır:\nRetrieval (Getirme):\nKullanıcı sorusu ile ilgili dokümanlar veya bilgiler veritabanından çekilir Semantic search kullanılarak en alakalı içerikler bulunur Embedding benzerliği ile dokümanlar sıralanır Augmentation (Zenginleştirme):\nBulunan bilgiler LLM\u0026rsquo;e gönderilen prompt\u0026rsquo;a eklenir Bilgiler önem sırasına göre düzenlenir Bağlam penceresi optimize edilir Generation (Üretim):\nLLM, zenginleştirilmiş bağlamı kullanarak yanıt üretir Yanıt, verilen kaynaklara referans verebilir Güvenilirlik skoru hesaplanabilir RAG\u0026rsquo;ın avantajları:\nGüncel bilgi kullanımı Doğruluk oranının artması Özelleştirilmiş yanıtlar Hallüsinasyonların azalması Kaynakların takip edilebilirliği Dinamik bilgi güncelleme imkanı Domain-specific bilgi entegrasyonu Vector DB Vector veritabanları, embedding vektörlerini depolamak ve bu vektörler üzerinde benzerlik araması yapmak için özelleştirilmiş veritabanı sistemleridir. Geleneksel veritabanlarından farklı olarak, vektörler arasındaki benzerliği hızlı bir şekilde hesaplayabilirler.\nVector DB\u0026rsquo;lerin temel özellikleri:\nYüksek boyutlu vektörleri verimli şekilde depolama Benzerlik bazlı arama (cosine similarity, euclidean distance) Hızlı yakın komşu (nearest neighbor) sorguları Ölçeklenebilirlik CRUD operasyonları Metadata filtreleme Batch işlem desteği Vektör indeksleme Vector DB\u0026rsquo;ler özellikle şu alanlarda kullanılır:\nSemantik doküman araması Öneri sistemleri Görüntü ve ses benzerliği analizi Doğal dil işleme uygulamaları Yüz tanıma sistemleri Anomali tespiti Çapraz modal arama (text-to-image, image-to-text) Popüler Vector DB çözümleri:\nPinecone: Tam yönetilen, ölçeklenebilir çözüm Weaviate: Açık kaynak, self-hosted seçeneği Milvus: Yüksek performanslı, dağıtık mimari Qdrant: Rust tabanlı, hızlı ve hafif ChromaDB: Python odaklı, başlangıç için ideal 3. Tool Calling: AI\u0026rsquo;a Yeni Yetenekler Kazandırma Tool Calling Nedir? Tool calling (araç çağırma), bir AI modelinin dış fonksiyonları veya API\u0026rsquo;leri çağırabilme yeteneğidir. Bu, AI\u0026rsquo;ın kendi bilgi sınırları dışındaki işlemleri gerçekleştirmesini sağlar.\nModern LLM\u0026rsquo;ler, JSON formatında araç çağrısı yapabilme yeteneğine sahiptir. Bu, modelin gerçekleştirmek istediği eylemi ve gerekli parametreleri tanımlamasını sağlar.\nNode.js ile Tool Calling OpenAI API\u0026rsquo;sini kullanarak tool calling implementasyonu yapalım. Aşağıdaki örnekte, Node.js kullanarak \u0026ldquo;tool calling\u0026rdquo; kavramını gösteren bir agent oluşturuyoruz. Bu agent iki farklı \u0026ldquo;aracı\u0026rdquo; çağırıyor:\nHava Durumu API\u0026rsquo;si (OpenWeatherMap): Agent, belirli bir konum için güncel hava durumu verisini alıyor. - OpenAI API: Aldığı hava durumu verisini kullanarak, günün nasıl geçtiğine dair kısa bir analiz istiyor. Bu iki aracı ardışık şekilde kullanarak, ajanın dış kaynaklardan veri toplayıp bu veriyi işlediğini görebiliriz.\nÖncelikle gerekli kütüphaneleri indiriyoruz\nnpm install axios openai Örnek kodumuz ise aşağıdaki şekilde.\nconst axios = require(\u0026#39;axios\u0026#39;); const { OpenAI } = require(\u0026#39;openai\u0026#39;); // API anahtarlarınızı girin const WEATHER_API_KEY = \u0026#39;\u0026lt;your-api-key\u0026gt;\u0026#39;; // OpenWeatherMap API anahtarınız // Hava durumu sorgulanacak konum const LOCATION = \u0026#39;Istanbul\u0026#39;; // OpenAI yapılandırması const openai = new OpenAI({ apiKey: \u0026#39;\u0026lt;your-api-key\u0026gt;\u0026#39;, }); // 1. Adım: Hava Durumu API\u0026#39;sini çağıran fonksiyon async function getWeatherData(location) { try { const response = await axios.get( `https://api.openweathermap.org/data/2.5/weather?q=${location}\u0026amp;appid=${WEATHER_API_KEY}\u0026amp;units=metric` ); return response.data; } catch (error) { console.error(\u0026#39;Hava durumu API hatası:\u0026#39;, error); return null; } } // 2. Adım: OpenAI API\u0026#39;ye veriyi gönderip analiz yapan fonksiyon async function analyzeWeather(weatherData) { if (!weatherData) return \u0026#39;Hava durumu verisi alınamadı.\u0026#39;; // Hava durumu verisine dayalı prompt oluşturma const prompt = `Şu an ${weatherData.name}\u0026#39;de hava ${weatherData.weather[0].description} ve sıcaklık ${weatherData.main.temp}°C. Bu hava durumuna göre, gün nasıl geçiyor ve ne tür bir aktivite önerirsiniz? Kısa bir özet ver.`; try { const response = await openai.chat.completions.create({ model: \u0026#39;gpt-4o-mini\u0026#39;, messages: [{ role: \u0026#39;user\u0026#39;, content: prompt }], max_tokens: 60, temperature: 0.7, }); return response.choices[0].message.content.trim(); } catch (error) { console.error(\u0026#39;OpenAI API hatası:\u0026#39;, error); return \u0026#39;Hava durumu analiz edilemedi.\u0026#39;; } } // Ana fonksiyon: Araçları sırasıyla çağırır async function main() { console.log(\u0026#39;Tool Calling Ajanı başlatılıyor...\u0026#39;); // Hava durumu verisini almak için aracı çağırma const weatherData = await getWeatherData(LOCATION); console.log(\u0026#39;Alınan Hava Durumu Verisi:\u0026#39;, weatherData); // OpenAI API\u0026#39;ye veriyi gönderip analiz alıyoruz const analysis = await analyzeWeather(weatherData); console.log(\u0026#39;Analiz Sonucu:\u0026#39;, analysis); } main(); Bu örnekte, agent \u0026ldquo;tool calling\u0026rdquo; yaparak iki farklı dış kaynağı (OpenWeatherMap ve OpenAI) kullanıyor. Öncelikle hava durumu verisi toplanıyor; ardından bu veri, bir analiz için OpenAI API\u0026rsquo;sine gönderiliyor. Böylece, ajanın kendi yeteneklerinin ötesinde dış kaynaklardan faydalanması sağlanıyor.\nFarklı Araç Türleri AI sistemlerinize entegre edebileceğiniz bazı araç türleri:\nVeritabanı İşlemleri: Veri sorgulama, ekleme, güncelleme API Çağrıları: Harici servislere bağlanma (hava durumu, borsa, haberler) Dosya İşlemleri: Dosya okuma, yazma, dönüştürme Hesaplamalar: Karmaşık matematiksel işlemler Takvim/Zamanlama: Etkinlik oluşturma, hatırlatıcı ayarlama Tool Calling Best Practices Açık Tanımlamalar: Araçlarınızı açık ve net tanımlayın, parametreleri dokumentasyon içerisinde detaylandırın Güvenlik Kontrolleri: Kullanıcı girdilerini doğrulayın Graceful Failure: Araçlar hata verdiğinde zarif bir şekilde geri dönüş yapın Aşamalı Geliştirme: Önce basit araçlarla başlayın, sonra karmaşıklığı artırın 4. Conversation Memory: AI\u0026rsquo;ya Hafıza Kazandırma Conversation Memory Nedir? Conversation memory, bir AI sisteminin önceki etkileşimleri hatırlama ve buna göre yanıt verme yeteneğidir. Bu özellik, sohbetin tutarlı ve bağlamsal olmasını sağlar.\nNeden Önemli? Bağlamsal tutarlılık sağlar. Kullanıcılar her seferinde bağlam vermek zorunda kalmaz. Yani diyalog sırasında, agent önceki mesajları \u0026lsquo;hatırlar\u0026rsquo;. Böylece, örneğin bir sohbet başlangıcından verilen bilgiler, sonraki yanıtların daha anlamlı ve tutarlı olmasını sağlar. AI, önceki isteklere referans verebilir Daha doğal ve insana benzer etkileşimler sağlar Conversation memory için örnek bir kullanımdan şu şekilde bahsedebiliriz. Bir chatbot, kullanıcının adını, ilgili alanlarını ya da daha önce sorduğu soruları belleğinde tutarak, sonraki yanıtlarda bu bilgileri referans alır. Böylece, her mesaj birbirine bağlı hale gelir ve sohbet bir doğal bir akış kazanır. Bu bellek genellikle, önceki mesajların belirli bir kısmını saklayarak gerçekleştirilir. Dil modelleri, bu geçmiş bilgiyi input olarak kullanarak, daha iyi bir bağlam anlayışı ile yanıt üretir. Konuşma belleğinin etkin kullanımı, bellek boyutu ve uzun diyaloglarda bilgilerin güncelliğini koruma gibi zorlukları da beraberinde getirir. Sonuç olarak, konuşma belleği yani conversation memory, AI Agent\u0026rsquo;larının daha \u0026lsquo;akıılı\u0026rsquo; ve bağlamsal yanıtlar üretebilmesi için kritik bir bileşendir. Bu özellik, uzun ve anlamlı sohbetler kurulmasına olanak tanır.\nNode.js ile Conversation Memory Aşağıdaki örnek; conversation memory tutan bir chatbot örneği. Bu örnekte her kullanıcının sohbet geçmişi MongoDB\u0026rsquo;de tutuluyor ve yeni bir mesaj geldiğinde geçmişi prpmpt olarak OpenAI\u0026rsquo;ya gönderiyoruz.\nÖnce gerekli kütüphaneleri yükleyelim:\nnpm install mongodb express openai Örnek kodumuz ise aşağıdaki şekilde:\nconst express = require(\u0026#39;express\u0026#39;); const { MongoClient } = require(\u0026#39;mongodb\u0026#39;); const { OpenAI } = require(\u0026#39;openai\u0026#39;); const app = express(); app.use(express.json()); const OPENAI_API_KEY = \u0026#39;\u0026lt;your-api-key\u0026gt;\u0026#39;; const MONGO_URI = \u0026#39;mongodb://localhost:27017\u0026#39;; const DATABASE_NAME = \u0026#39;conversationDB\u0026#39;; const COLLECTION_NAME = \u0026#39;conversations\u0026#39;; // OpenAI yapılandırması const openai = new OpenAI({ apiKey: OPENAI_API_KEY, }); // MongoDB bağlantısı const client = new MongoClient(MONGO_URI, { useUnifiedTopology: true }); let conversationCollection; client .connect() .then(() =\u0026gt; { const db = client.db(DATABASE_NAME); conversationCollection = db.collection(COLLECTION_NAME); console.log(\u0026#34;MongoDB\u0026#39;ye bağlanıldı.\u0026#34;); }) .catch((err) =\u0026gt; console.error(\u0026#39;MongoDB bağlantı hatası:\u0026#39;, err)); // Chat endpoint\u0026#39;i app.post(\u0026#39;/chat\u0026#39;, async (req, res) =\u0026gt; { const { userId, message } = req.body; if (!userId || !message) { return res.status(400).send({ error: \u0026#39;userId ve message gerekli.\u0026#39; }); } try { // Kullanıcının önceki sohbet geçmişini al let conversation = await conversationCollection.findOne({ userId }); if (!conversation) { conversation = { userId, messages: [] }; } // Kullanıcı mesajını geçmişe ekle conversation.messages.push({ role: \u0026#39;user\u0026#39;, content: message }); // Konuşma geçmişini prompt\u0026#39;a dönüştür let prompt = \u0026#39;\u0026#39;; conversation.messages.forEach((msg) =\u0026gt; { prompt += (msg.role === \u0026#39;user\u0026#39; ? \u0026#39;Kullanıcı\u0026#39; : \u0026#39;Ajan\u0026#39;) + `: ${msg.content}\\n`; }); prompt += \u0026#39;Ajan:\u0026#39;; // Ajanın yanıt vermesi için // OpenAI API çağrısı const response = await openai.chat.completions.create({ model: \u0026#39;gpt-4o-mini\u0026#39;, messages: [{ role: \u0026#39;user\u0026#39;, content: prompt }], max_tokens: 100, temperature: 0.7, }); const agentReply = response.choices[0].message.content.trim(); // Ajan yanıtını geçmişe ekle conversation.messages.push({ role: \u0026#39;agent\u0026#39;, content: agentReply }); // Güncellenmiş sohbeti MongoDB\u0026#39;ye kaydet (upsert) await conversationCollection.updateOne({ userId }, { $set: { messages: conversation.messages } }, { upsert: true }); res.send({ reply: agentReply }); } catch (error) { console.error(\u0026#39;Sohbet işlenirken hata:\u0026#39;, error); res.status(500).send({ error: \u0026#39;Sunucu hatası\u0026#39; }); } }); app.listen(3000, () =\u0026gt; { console.log(\u0026#39;Sunucu 3000 portunda çalışıyor.\u0026#39;); }); Bu örnek kodda, her kullanıcının sohbet geçmişi userId ile MongoDB\u0026rsquo;de saklanıyor. Yeni bir mesaj geldiğinde, bu geçmiş alınarak OpenAI prompt\u0026rsquo;una dahil ediliyor. Böylece, model önceki konuşmayı da göz önünde bulundarak yanıt üretiyor.\nÖrnek cURL isteği:\ncurl --location \u0026#39;http://localhost:3000/chat\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data \u0026#39;{ \u0026#34;userId\u0026#34;: \u0026#34;123\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;istanbul\u0026#39;da hava kaç derece\u0026#34; }\u0026#39; Örnek senaryo ise şu şekilde gelişebilir: User =\u0026gt; bugün İstanbul\u0026rsquo;da hava kaç derece Agent =\u0026gt; İstanbul\u0026rsquo;da hava 23 derece ve güneşli User =\u0026gt; peki ya İzmir? Agent=\u0026gt; İzmir\u0026rsquo;de hava 26 derece ve güneşli.\nAgent burada geçmişi tuttuğu için ikinci soruda \u0026lsquo;hava durumu\u0026rsquo; vb. kelimeler geçmemesine rağmen sadece \u0026lsquo;peki ya İzmir\u0026rsquo; seçeneğinden sohbet gemmişini tuttuğu için hava durumuu bilgisini alacak ve ona göre cevabı verecektir.\n5. Model Context Protocol: LLM Bağlamını Yönetme Model Context Protocol yani MCP; bir dil modeline (örneğin GPT-4, Claude 3.7 Sonnet) hangi bilgilerin, hangi formatta ve nasıl sağlanacağına dair belirli kuralları ve yapılandırmaları ifade eder. Bu kavramı daha iyi anlamak için aşağıdaki başlıklara da değinelim.\nBağlamın Tanımlanması ve Formatlanması Bağlam Nedir =\u0026gt; Dil modelleri, yanıt üretirken sadece kendilerine gönderilen girdiye (prompt) dayanır. Bu girdi, sohbetin geçmişi, sistem yönergeleri, kullanıcı soruları ve hatta araç çağrılarından elde edilen veriler gibi çeşitli unsurları içerebilir. Protokol Nedir =\u0026gt; Protokol ifadesi, bu bilgilerin nasıl düzenleneceğini, sıralanacağını ve formatlanacağını belirleyen kuralları ifade eder. Örneğin OpenAI\u0026rsquo;nın ChatGPT modeli, sohbet geçmişini \u0026lsquo;system\u0026rsquo;, \u0026lsquo;user\u0026rsquo; ve \u0026lsquo;assistant\u0026rsquo; rolleriyle ayırır. Bu yapı, modelin hangi bilgileri öncelikli olarak dikkate alacağını belirler. Konuşma Belleği ve Bağlam Yönetimi Konuşma Belleği =\u0026gt; Konuşma belleği, önceki mesajların hatırlanmasını sağlayan bir mekanizmadır. Ancak model, durum bilgisini doğrudan saklamaz; her seferinde önceki mesajlar prompt\u0026rsquo;a eklenerek bağlam sağlanır. Token Sınırı =\u0026gt; Modellerin işleyebileceği toplam token sayısı sınırlıdır. Bu nedenle, hangi geçmiş mesajların dahil edileceği, hangi bilgilerin özetleneceği gibi kararlar \u0026ldquo;model context protocol\u0026rdquo; kapsamında ele alınır. Bu, modelin en alakalı bilgiyi görmesini sağlar. Dinamik ve Statik Bilgiler Dinamik Bilgiler =\u0026gt; Sohbet sırasında sürekli güncellenen bilgiler (örneğin, kullanıcı mesajları, araçlardan gelen yanıtlar) dinamik bağlamın bir parçası olarak prompt\u0026rsquo;a eklenir. Statik Bilgiler =\u0026gt; Bazı sistem yönergeleri, modelin nasıl davranması gerektiğini belirten sabit komutlar veya bilgiler de olabilir. Örneğin, modelin belirli bir ton veya dilde yanıt vermesini istemek gibi. Uygulama Örneği Diyelim ki bir chatbot oluşturuyoruz. MCP bu chatbot projesinde şu mantıkla çalışabilir Sistem Mesajı =\u0026gt; \u0026ldquo;Bu bir müşteri destek sohbetidir. Cevaplarını nazik ve yardımcı bir üslupla ver.\u0026rdquo; Kullanıcı Mesajları =\u0026gt; \u0026ldquo;Merhaba, hesabımda sorun var\u0026rdquo; gibi geçmiş mesajlar. Araç Çağrıları =\u0026gt; Eğer dış API\u0026rsquo;lerden veri alınıyorsa, bu verilerde uygun şekilde prompt\u0026rsquo;a dahil edilir. Prompt Oluşturma =\u0026gt; Tüm bu bilgiler belirli bir sırayla ve formatla (örneğin, Kullanıcı: \u0026hellip;, Agent: \u0026hellip;) birleştirilir ve modelin yanıt üretmesi için gönderilir. Özetleyecek olursak MCP, dil modeline hangi bilgilerin verileceğini, bu bilgilerin nasıl yapılandırılacağını ve modelin nasıl daha etkili yanıtlar üreteceğini belirleyen bir rehber gibidir. Doğru bir protokol oluşturmak, modelin bağlamı daha iyi anlamasına ve daha tutarlı, alakalı cevaplar vermesine yardımcı olur. Bu kavram, özellikle uzun ve karmaşık diyaloglarda, doğru bilgiyi modelin anlayabileceği sınır dahilinde tutmak için kritik bir öneme sahiptir.\n6. Fine-tuning: LLM\u0026rsquo;leri Özelleştirme Fine-tuning, önceden eğitilmiş bir dil modelini (LLM) belirli bir görev veya domain için özelleştirme sürecidir. Bu süreç, modelin belirli bir kullanım senaryosu için daha doğru ve tutarlı yanıtlar üretmesini sağlar.\nFine-tuning Ne Zaman Kullanılmalı? Fine-tuning şu durumlarda özellikle faydalıdır:\nÖzel domain bilgisi gerektiren görevler Tutarlı format veya stil gerektiren çıktılar Marka sesi ve ton uyumu gereken durumlar Teknik terminoloji kullanımı Çok sayıda benzer görev tekrarı Fine-tuning Avantajları Daha İyi Performans:\nDomain-specific görevlerde daha doğru yanıtlar Daha tutarlı çıktı formatı Azaltılmış hallüsinasyonlar Maliyet Optimizasyonu:\nDaha kısa promptlar kullanabilme Daha az token tüketimi Daha hızlı yanıt süreleri Özelleştirilmiş Davranış:\nMarka diline uygun yanıtlar Tutarlı ton ve üslup Özel kuralları öğrenebilme Fine-tuning Süreci Veri Hazırlama:\nEğitim verisi toplama Veri temizleme ve formatlama Prompt-completion çiftleri oluşturma Model Seçimi:\nBase model belirleme Model parametrelerini ayarlama Eğitim stratejisi seçimi Eğitim:\nHiperparametre optimizasyonu Eğitim metriklerini izleme Cross-validation kontrolleri Değerlendirme:\nModel performans analizi A/B testleri İnsan değerlendirmesi Fine-tuning Best Practices Veri Kalitesi:\nYüksek kaliteli eğitim verisi kullanın Veri çeşitliliğini sağlayın Dengeli veri dağılımı oluşturun Model Seçimi:\nGörev için uygun boyutta model seçin Maliyet-performans dengesini gözetin Base model performansını değerlendirin Eğitim Stratejisi:\nKademeli fine-tuning uygulayın Overfitting\u0026rsquo;i önleyin Düzenli değerlendirme yapın Deployment:\nModel versiyonlaması yapın Performans izleme mekanizmaları kurun Geri bildirim döngüsü oluşturun 7. Ollama, LiteLLM, LlamaCPP: Açık Kaynak AI Çözümleri Açık kaynaklı LLM\u0026rsquo;ler ve araçlar, AI geliştirme süreçlerini daha erişilebilir hale getiriyor. Bu bölümde, Node.js uygulamalarınızda kullanabileceğiniz popüler açık kaynak AI çözümlerini inceleyeceğiz.\nOllama: Ollama, kullanıcıların büyük dil modellerini (ör. LLaMA, GPT türevi modeller) kendi makinelerinde çalıştırmasını sağlayan, genellikle kullanıcı dostu bir arayüz sunan platformlardır. Bu tür uygulamalar, modelin kurulumu, güncellemeleri ve entegrasyonunu kolaylaştırmak amacıyla tasarlanır; böylece, kullanıcının internet bağlantısına bağımlı olmadan yerel olarak güvenli ve hızlı erişim sağlanabilir. LiteLLM: Litellm, \u0026ldquo;lightweight\u0026rdquo; yani hafif anlamına gelen bir yaklaşımla geliştirilmiş, büyük dil modelleriyle çalışmayı kolaylaştıran bir kütüphane ya da araçtır. Genellikle minimal kaynak kullanımı, esneklik ve hızlı prototipleme imkanı sunar. Bu tür araçlar, model eğitiminden ziyade, var olan büyük modellerin daha az kaynakla çalıştırılmasına odaklanır. LlamaCpp: LlamaCpp, Meta\u0026rsquo;nın LLaMA modeli gibi büyük dil modellerinin C++ ile optimize edilmiş bir implementasyonudur. Bu kütüphane, özellikle quantized (azaltılmış hassasiyetli) modelleri CPU üzerinde verimli bir şekilde çalıştırmayı hedefler. Böylece, güçlü GPU\u0026rsquo;lara ihtiyaç duymadan, yerel makinede LLM çalıştırmak mümkün hale gelir. Açık Kaynak AI Çözümleri Karşılaştırması Özellik Ollama LiteLLM LlamaCPP Kurulum Kolaylığı ★★★★★ ★★★★☆ ★★☆☆☆ Performans ★★★★☆ ★★★★☆ ★★★★★ API Uyumluluğu ★★★☆☆ ★★★★★ ★★☆☆☆ Kaynak Kullanımı ★★★☆☆ ★★★★☆ ★★★★★ Çoklu Model Desteği ★★★★☆ ★★★★★ ★★★☆☆ Maliyet Ücretsiz Ücretsiz* Ücretsiz Özetle, hepsi büyük dil modellerinin yerel veya optimize edilmiş ortamlarda kullanımını kolaylaştırmaya yönelik araçlar olsa da;\nOllama daha kapsamlı bir platform olarak, kullanımı basitleştirip entegre çözümler sunarken, Litellm hafif ve modüler yapısıyla geliştiricilere esneklik sağlamak istiyor, LlamaCpp ise özellikle performans ve düşük kaynak kullanımı açısından C++ ile optimize edilmiş bir çözüm sunuyor. Bu araçlar, hangi donanım ve kullanım senaryosunda çalıştırılacağına göre tercih edilebilir. Böylece, örneğin geliştirici ortamınızda hızlı prototipleme yapmak için litellm kullanabilir, performans odaklı yerel uygulamalarda ise llamaCpp tercih edilebilir; Ollama ise daha kapsamlı bir kullanıcı deneyimi arayanlara hitap edebilir.\n8. N8n: AI İş Akışları Otomasyonu N8n, kod yazmadan veya minimum kod ile iş akışlarını otomatikleştirmenize olanak tanıyan açık kaynaklı bir otomasyon aracıdır. N8n\u0026rsquo;in esnek yapısı, AI hizmetlerini diğer uygulamalarla kolayca entegre etmenizi sağlar. N8N, tamamen açık kaynaklıdır; bu sayede kaynak koduna erişebilir, özelleştirebilir ve kendi ihtiyaçlarınıza göre uyarlayabilirsiniz. Sürükle bırak arayüzü sayesinde, her biri belirli bir işlemi yapan \u0026ldquo;node\u0026quot;lardan oluşan akışlar tasarlayabilirsiniz. Bu sayede, teknik bilgisi az olan kullanıcılar bile karmaşık iş akışları oluşturabilir.\nN8N, çok sayıda API ve servisle enteagrasyon sağlayarak, örneğin e-posta, veritabanı, sosyal medya, dosya depolama gibi farklı sistemler arasında veri transferi veya otomatik işlemler yapmanıza olanak tanır. N8N\u0026rsquo;i kendi sunucularınızda barındırabilirsiniz. Bu, verilerin kontrolünün tamamen sizde olmasını sağlar ve özellikle gizlilik veya compliance konularında avantaj sunar.\nÖrneğin, bir müşteri destek sürecinde, e-posta aldığında otomatik olarak bir veritabanına kayıt eklemek, ardından Slack üzerinden bildirim göndermek istiyorsan, n8n ile bu adımları görsel olarak düzenleyip otomatik hale getirebilirsin.\nN8n ile Yapılabilecek AI İş Akışları Belge İşleme ve Özetleme\nGelen e-posta eklerini otomatik olarak özetleme PDF belgeleri analiz edip veri çıkarma Müşteri Destek Otomasyonu\nGelen müşteri sorularını analiz edip sınıflandırma Basit sorulara otomatik yanıt oluşturma, karmaşık soruları yönlendirme Sosyal Medya Yönetimi\nBelirli konularda otomatik içerik üretme Yorumları duygu analizi ile sınıflandırma ve yanıtlama Veri Analizi ve Raporlama\nPeriyodik verileri analiz etme ve özetleme Veri anormalliklerini tespit edip uyarı gönderme N8n ve AI Entegrasyonunun Avantajları Kod Yazmadan Otomasyon: Teknik olmayan ekip üyeleri bile komplex AI iş akışları oluşturabilir Çoklu Servis Entegrasyonu: 200+ entegrasyon ile AI\u0026rsquo;ı tüm iş süreçlerinize dahil edebilirsiniz Self-Hosting: Hassas veriler içeren AI işlemleri için kendi altyapınızda çalıştırabilirsiniz Esnek Tetikleyiciler: Zamanlayıcı, webhook, olay bazlı tetikleyiciler ile AI işlemlerini başlatabilirsiniz Son Söz AI teknolojileri hızla gelişiyor ve bu teknolojilerin Node.js ekosistemindeki entegrasyonu giderek kolaylaşıyor. Bu makalede gördüğümüz teknikler, AI destekli uygulamalar geliştirmek için sağlam bir temel oluşturuyor.\nAI agent\u0026rsquo;lar, tool calling, conversation memory ve bağlam yönetimi gibi temel kavramların yanı sıra, embedding\u0026rsquo;ler, RAG (Retrieval Augmented Generation) ve vector veritabanları gibi modern AI teknolojilerini kullanarak daha güçlü ve akıllı uygulamalar geliştirebilirsiniz. Fine-tuning ile modellerinizi özelleştirerek, domain-specific görevlerde daha başarılı sonuçlar elde edebilirsiniz.\nAçık kaynak modeller ve N8n gibi otomasyon araçlarıyla birlikte, bu teknolojileri kullanarak:\nDaha doğru ve bağlama duyarlı yanıtlar üreten chatbot\u0026rsquo;lar Akıllı doküman işleme ve analiz sistemleri Semantik arama ve öneri motorları Otomatikleştirilmiş iş akışları Domain-specific AI asistanları gibi çözümler geliştirebilirsiniz.\nBu makalede gösterilen tüm kod örneklerine ve daha fazlasına GitHub Repository adresinden erişebilirsiniz.\nYapay zeka yolculuğunuzda başarılar dilerim!\n",
    "tags": ["ai","nodejs"],
    "categories": ["AI","Node.js","JavaScript"],
    "lang": "tr"
} 