<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" 
    xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI on Çağatay Türkan</title>
    <link>https://cagatayturkan.com/blog/en/categories/ai/</link>
    <description>Recent content in AI on Çağatay Türkan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Mar 2025 10:00:00 +0300</lastBuildDate><atom:link href="https://cagatayturkan.com/blog/en/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RAG: Building Next-Generation AI Systems with Retrieval Augmented Generation</title>
      <link>https://cagatayturkan.com/blog/en/rag-building-next-gen-ai-systems/</link>
      <pubDate>Thu, 13 Mar 2025 10:00:00 +0300</pubDate>
      
      <guid>https://cagatayturkan.com/blog/en/rag-building-next-gen-ai-systems/</guid>
      <description>This article explores the fundamentals of Retrieval Augmented Generation (RAG), how it enhances LLM capabilities through external knowledge retrieval, and its practical applications across industries. We&amp;rsquo;ll examine RAG architecture, implementation strategies, and best practices for creating more accurate, reliable, and context-aware AI systems.</description>
      
      <cardimage>https://cagatayturkan.com/blog/en/rag-building-next-gen-ai-systems/images/cover.svg</cardimage>
      
      
      <featureimage>https://cagatayturkan.com/blog/en/rag-building-next-gen-ai-systems/images/cover.svg</featureimage>
      
      <content:encoded>&lt;h1 id=&#34;rag-building-next-generation-ai-systems-with-retrieval-augmented-generation&#34;&gt;RAG: Building Next-Generation AI Systems with Retrieval Augmented Generation&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Large Language Models (LLMs) have revolutionized how machines understand and generate human language. However, despite their impressive capabilities, these models have inherent limitations: they only know what they&amp;rsquo;ve been trained on, information may be outdated, and they occasionally &amp;ldquo;hallucinate&amp;rdquo; facts. Retrieval Augmented Generation (RAG) has emerged as a transformative approach to address these challenges by combining the generative power of LLMs with the precision of information retrieval systems.&lt;/p&gt;
&lt;p&gt;In this article, we&amp;rsquo;ll explore:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The fundamental principles and architecture of RAG systems&lt;/li&gt;
&lt;li&gt;How RAG enhances LLM capabilities and overcomes their limitations&lt;/li&gt;
&lt;li&gt;Key components of effective RAG implementations&lt;/li&gt;
&lt;li&gt;Advanced techniques for optimizing RAG performance&lt;/li&gt;
&lt;li&gt;Real-world applications across different industries&lt;/li&gt;
&lt;li&gt;Best practices and future directions for RAG technology&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;1-understanding-rag-principles-and-architecture&#34;&gt;1. Understanding RAG: Principles and Architecture&lt;/h2&gt;
&lt;h3 id=&#34;what-is-retrieval-augmented-generation&#34;&gt;What is Retrieval Augmented Generation?&lt;/h3&gt;
&lt;p&gt;Retrieval Augmented Generation (RAG) is an AI framework that enhances language models by incorporating external knowledge sources. Instead of relying solely on information encoded in the model&amp;rsquo;s parameters, RAG retrieves relevant documents or data from an external knowledge base and uses this information to generate more accurate, current, and context-aware responses.&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cagatayturkan.com/blog/blog/en/rag-building-next-gen-ai-systems/images/ragArchitecture.svg&#34;
    alt=&#34;Diagram showing basic RAG architecture with user query flow through retriever and generator components&#34;&gt;
&lt;/figure&gt;

&lt;p&gt;The core architecture of a RAG system consists of two primary components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Retriever&lt;/strong&gt;: Responsible for finding and retrieving relevant information from the knowledge base&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generator&lt;/strong&gt;: The language model that uses both the retrieved information and its own parametric knowledge to generate the final response&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This hybrid approach combines the strengths of both systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The retriever provides factual precision, up-to-date information, and domain-specific knowledge&lt;/li&gt;
&lt;li&gt;The generator contributes language understanding, reasoning capabilities, and natural language generation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-evolution-of-rag&#34;&gt;The Evolution of RAG&lt;/h3&gt;
&lt;p&gt;RAG has evolved significantly since its introduction:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Early Information Retrieval&lt;/strong&gt;: Traditional search engines relied on keyword matching, which often missed semantic meaning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neural Information Retrieval&lt;/strong&gt;: Introduced neural networks to better understand semantic relationships&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dense Passage Retrieval&lt;/strong&gt;: Improved embedding-based approaches for more accurate document retrieval&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modern RAG Systems&lt;/strong&gt;: Combine sophisticated retrieval mechanisms with powerful generative models&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each evolutionary step has enhanced the system&amp;rsquo;s ability to find and incorporate relevant knowledge into the generation process.&lt;/p&gt;
&lt;h2 id=&#34;2-key-components-of-effective-rag-systems&#34;&gt;2. Key Components of Effective RAG Systems&lt;/h2&gt;
&lt;h3 id=&#34;knowledge-base-construction&#34;&gt;Knowledge Base Construction&lt;/h3&gt;
&lt;p&gt;The foundation of any RAG system is its knowledge base—the external repository of information that the model can access. Creating an effective knowledge base involves several critical considerations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Selection and Curation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose authoritative, accurate sources&lt;/li&gt;
&lt;li&gt;Ensure data diversity and comprehensive coverage&lt;/li&gt;
&lt;li&gt;Maintain information quality and consistency&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Document Processing&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Text extraction from various formats (PDF, HTML, etc.)&lt;/li&gt;
&lt;li&gt;Cleaning and normalization&lt;/li&gt;
&lt;li&gt;Metadata enrichment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Chunking Strategies&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Document segmentation into appropriate-sized chunks&lt;/li&gt;
&lt;li&gt;Semantic vs. fixed-size chunking&lt;/li&gt;
&lt;li&gt;Chunk overlap considerations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The quality, coverage, and organization of the knowledge base significantly impact the overall performance of a RAG system.&lt;/p&gt;
&lt;h3 id=&#34;embedding-and-vector-representations&#34;&gt;Embedding and Vector Representations&lt;/h3&gt;
&lt;p&gt;At the heart of modern RAG systems is the conversion of text into numerical vector representations (embeddings) that capture semantic meaning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embedding Generation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Text is transformed into high-dimensional vectors (typically 768-4096 dimensions)&lt;/li&gt;
&lt;li&gt;Similar meanings are positioned close to each other in vector space&lt;/li&gt;
&lt;li&gt;Different embedding models prioritize different semantic aspects&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Properties of Good Embeddings&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semantic similarity is reflected in vector proximity&lt;/li&gt;
&lt;li&gt;Robust to paraphrasing and linguistic variations&lt;/li&gt;
&lt;li&gt;Dimension-efficient representation of meaning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Embedding Model Selection&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;General-purpose vs. domain-specialized embeddings&lt;/li&gt;
&lt;li&gt;Size vs. performance tradeoffs&lt;/li&gt;
&lt;li&gt;Cross-lingual capabilities&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;&lt;img src=&#34;https://cagatayturkan.com/blog/blog/en/rag-building-next-gen-ai-systems/images/textEmbeddings.svg&#34;
    alt=&#34;Visualization of text embeddings in 2D/3D space showing semantic clustering&#34;&gt;
&lt;/figure&gt;

&lt;h3 id=&#34;vector-database-technologies&#34;&gt;Vector Database Technologies&lt;/h3&gt;
&lt;p&gt;Vector databases are specialized storage systems designed for efficient similarity search across high-dimensional vectors. They serve as the retrieval engine in RAG systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Key Vector Database Features&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Approximate Nearest Neighbor (ANN) algorithms for fast retrieval&lt;/li&gt;
&lt;li&gt;Indexing techniques that balance accuracy and speed&lt;/li&gt;
&lt;li&gt;Filtering capabilities based on metadata&lt;/li&gt;
&lt;li&gt;Scalability to billions of vectors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Popular Vector Database Options&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pinecone: Fully-managed, scalable vector search&lt;/li&gt;
&lt;li&gt;Weaviate: Open-source, semantic search engine&lt;/li&gt;
&lt;li&gt;Milvus: High-performance, distributed architecture&lt;/li&gt;
&lt;li&gt;Qdrant: Rust-based, lightweight, and flexible&lt;/li&gt;
&lt;li&gt;ChromaDB: Python-focused, easy to get started&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice of vector database significantly impacts retrieval speed, accuracy, and the overall system&amp;rsquo;s scalability.&lt;/p&gt;
&lt;h2 id=&#34;3-the-rag-pipeline-from-query-to-response&#34;&gt;3. The RAG Pipeline: From Query to Response&lt;/h2&gt;
&lt;h3 id=&#34;query-processing-and-understanding&#34;&gt;Query Processing and Understanding&lt;/h3&gt;
&lt;p&gt;The RAG process begins with the user&amp;rsquo;s input query. Effective query processing involves:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Query Analysis&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intent recognition&lt;/li&gt;
&lt;li&gt;Entity extraction&lt;/li&gt;
&lt;li&gt;Constraint identification&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Query Transformation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Query expansion (adding related terms)&lt;/li&gt;
&lt;li&gt;Query refinement (focusing on key elements)&lt;/li&gt;
&lt;li&gt;Rewriting for retrieval optimization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Query Embedding&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Converting the query to the same vector space as the knowledge base&lt;/li&gt;
&lt;li&gt;Applying the same embedding model used for documents&lt;/li&gt;
&lt;li&gt;Preserving the semantic intent in the vector representation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;multi-stage-retrieval-strategies&#34;&gt;Multi-stage Retrieval Strategies&lt;/h3&gt;
&lt;p&gt;Modern RAG systems often employ sophisticated multi-stage retrieval pipelines:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Initial Broad Retrieval&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semantic search using embedding similarity&lt;/li&gt;
&lt;li&gt;High recall, moderate precision&lt;/li&gt;
&lt;li&gt;Retrieves candidate documents from the vector database&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Re-ranking and Refinement&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More computationally intensive scoring of initial results&lt;/li&gt;
&lt;li&gt;Cross-attention between query and documents&lt;/li&gt;
&lt;li&gt;Re-ordering based on relevance scores&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Hybrid Retrieval Approaches&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Combining dense (embedding-based) and sparse (keyword-based) retrieval&lt;/li&gt;
&lt;li&gt;Ensemble methods across multiple retrievers&lt;/li&gt;
&lt;li&gt;Domain-specific retrieval strategies&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;&lt;img src=&#34;https://cagatayturkan.com/blog/blog/en/rag-building-next-gen-ai-systems/images/multiStageRetrieval.svg&#34;
    alt=&#34;Flowchart of multi-stage retrieval process with filters and re-ranking&#34;&gt;
&lt;/figure&gt;

&lt;h3 id=&#34;context-integration-and-response-generation&#34;&gt;Context Integration and Response Generation&lt;/h3&gt;
&lt;p&gt;The final stage in the RAG pipeline is generating a response using both the retrieved information and the LLM&amp;rsquo;s capabilities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Context Window Construction&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selecting the most relevant retrieved documents&lt;/li&gt;
&lt;li&gt;Ordering and structuring the context&lt;/li&gt;
&lt;li&gt;Managing token limits in the LLM prompt&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Engineering&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Crafting effective instructions for the LLM&lt;/li&gt;
&lt;li&gt;Specifying how to use the retrieved information&lt;/li&gt;
&lt;li&gt;Setting the tone, format, and constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Response Generation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM processes the query and retrieved context&lt;/li&gt;
&lt;li&gt;Synthesis of information into a coherent response&lt;/li&gt;
&lt;li&gt;Attribution to source documents when appropriate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;4-advanced-rag-techniques-and-optimizations&#34;&gt;4. Advanced RAG Techniques and Optimizations&lt;/h2&gt;
&lt;h3 id=&#34;recursive-retrieval-and-retrieval-augmented-retrieval&#34;&gt;Recursive Retrieval and Retrieval Augmented Retrieval&lt;/h3&gt;
&lt;p&gt;Standard RAG performs a single retrieval operation, but advanced implementations use multiple retrieval rounds:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recursive RAG&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial response generation&lt;/li&gt;
&lt;li&gt;Analysis of information gaps&lt;/li&gt;
&lt;li&gt;Secondary targeted retrievals to fill those gaps&lt;/li&gt;
&lt;li&gt;Final comprehensive response generation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Retrieval Augmented Retrieval&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using the LLM to help refine the retrieval process&lt;/li&gt;
&lt;li&gt;Generating better search queries based on initial results&lt;/li&gt;
&lt;li&gt;Iterative improvement of retrieval quality&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;query-decomposition-for-complex-questions&#34;&gt;Query Decomposition for Complex Questions&lt;/h3&gt;
&lt;p&gt;Complex queries often encompass multiple sub-questions or aspects. Query decomposition addresses this by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Breaking down complex queries into simpler sub-queries&lt;/li&gt;
&lt;li&gt;Performing separate retrievals for each sub-query&lt;/li&gt;
&lt;li&gt;Integrating the retrieved information for a comprehensive response&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This approach significantly improves performance on multi-hop reasoning tasks and complex analytical questions.&lt;/p&gt;
&lt;h3 id=&#34;hypothetical-document-embeddings-hyde&#34;&gt;Hypothetical Document Embeddings (HyDE)&lt;/h3&gt;
&lt;p&gt;HyDE is an innovative technique that enhances retrieval quality:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The LLM first generates a hypothetical perfect document that would answer the query&lt;/li&gt;
&lt;li&gt;This hypothetical document is embedded and used for retrieval instead of the original query&lt;/li&gt;
&lt;li&gt;The retrieval results are often more relevant than those from direct query embedding&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This technique leverages the LLM&amp;rsquo;s reasoning abilities to improve the retrieval process itself.&lt;/p&gt;
&lt;h3 id=&#34;knowledge-caching-and-retrieval-memory&#34;&gt;Knowledge Caching and Retrieval Memory&lt;/h3&gt;
&lt;p&gt;Efficient RAG systems can benefit from various caching mechanisms:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Session-Based Caching&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Retaining retrieved documents within a conversation&lt;/li&gt;
&lt;li&gt;Building a working memory of relevant information&lt;/li&gt;
&lt;li&gt;Reducing redundant retrievals&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cross-Session Knowledge Distillation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identifying frequently retrieved information&lt;/li&gt;
&lt;li&gt;Creating condensed knowledge summaries&lt;/li&gt;
&lt;li&gt;Prioritizing high-value information in the retrieval process&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-evaluating-rag-systems&#34;&gt;5. Evaluating RAG Systems&lt;/h2&gt;
&lt;h3 id=&#34;key-performance-metrics&#34;&gt;Key Performance Metrics&lt;/h3&gt;
&lt;p&gt;Measuring RAG performance requires a multifaceted approach:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Retrieval Metrics&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Precision: Accuracy of retrieved documents&lt;/li&gt;
&lt;li&gt;Recall: Comprehensiveness of retrieved information&lt;/li&gt;
&lt;li&gt;Mean Reciprocal Rank (MRR): Position of first relevant document&lt;/li&gt;
&lt;li&gt;Normalized Discounted Cumulative Gain (nDCG): Ranking quality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Generation Metrics&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Factual accuracy&lt;/li&gt;
&lt;li&gt;Hallucination rate&lt;/li&gt;
&lt;li&gt;Answer relevance&lt;/li&gt;
&lt;li&gt;Response completeness&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;End-to-End Metrics&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User satisfaction&lt;/li&gt;
&lt;li&gt;Query resolution rate&lt;/li&gt;
&lt;li&gt;Time-to-answer&lt;/li&gt;
&lt;li&gt;System latency&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;figure&gt;&lt;img src=&#34;https://cagatayturkan.com/blog/blog/en/rag-building-next-gen-ai-systems/images/mockupDashboardRagMetric.svg&#34;
    alt=&#34;Dashboard mockup showing key RAG performance metrics&#34;&gt;
&lt;/figure&gt;

&lt;h3 id=&#34;human-in-the-loop-evaluation&#34;&gt;Human-in-the-Loop Evaluation&lt;/h3&gt;
&lt;p&gt;Automated metrics provide valuable signals but should be complemented with human evaluation:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expert Review&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Domain specialists assessing factual correctness&lt;/li&gt;
&lt;li&gt;Identifying subtle errors or misconceptions&lt;/li&gt;
&lt;li&gt;Evaluating nuanced aspects of responses&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;User Feedback&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Direct ratings from end-users&lt;/li&gt;
&lt;li&gt;Implicit signals (follow-up questions, refinements)&lt;/li&gt;
&lt;li&gt;A/B testing of different RAG configurations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Continuous Improvement&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identifying patterns in errors or weaknesses&lt;/li&gt;
&lt;li&gt;Targeted enhancement of knowledge gaps&lt;/li&gt;
&lt;li&gt;Iterative refinement of retrieval strategies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;6-real-world-rag-applications&#34;&gt;6. Real-World RAG Applications&lt;/h2&gt;
&lt;h3 id=&#34;enterprise-knowledge-management&#34;&gt;Enterprise Knowledge Management&lt;/h3&gt;
&lt;p&gt;RAG systems are transforming how organizations access and leverage their institutional knowledge:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Internal Documentation Access&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Connecting employees with relevant policies, procedures, and documentation&lt;/li&gt;
&lt;li&gt;Reducing search time and improving information discovery&lt;/li&gt;
&lt;li&gt;Maintaining organizational knowledge continuity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Customer Support Enhancement&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Providing support agents with contextually relevant information&lt;/li&gt;
&lt;li&gt;Ensuring consistent and accurate responses&lt;/li&gt;
&lt;li&gt;Reducing resolution time for complex inquiries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Compliance and Governance&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensuring responses adhere to regulatory requirements&lt;/li&gt;
&lt;li&gt;Maintaining audit trails of information sources&lt;/li&gt;
&lt;li&gt;Reducing risk through accurate information retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;scientific-research-and-healthcare&#34;&gt;Scientific Research and Healthcare&lt;/h3&gt;
&lt;p&gt;The ability to retrieve and synthesize specialized knowledge makes RAG valuable in research and healthcare:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Literature Review Assistance&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Retrieving relevant research papers and findings&lt;/li&gt;
&lt;li&gt;Summarizing state-of-the-art knowledge&lt;/li&gt;
&lt;li&gt;Identifying connections across diverse studies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Clinical Decision Support&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Providing clinicians with relevant medical literature&lt;/li&gt;
&lt;li&gt;Retrieving case studies and treatment guidelines&lt;/li&gt;
&lt;li&gt;Supporting evidence-based medicine with the latest research&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Drug Discovery and Development&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Accessing information across pharmaceutical databases&lt;/li&gt;
&lt;li&gt;Synthesizing knowledge from diverse scientific domains&lt;/li&gt;
&lt;li&gt;Accelerating research through improved information access&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;education-and-learning&#34;&gt;Education and Learning&lt;/h3&gt;
&lt;p&gt;RAG is transforming educational experiences through personalized knowledge access:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Intelligent Tutoring Systems&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Retrieving explanations tailored to student questions&lt;/li&gt;
&lt;li&gt;Providing diverse learning resources on demand&lt;/li&gt;
&lt;li&gt;Adapting explanations to different learning styles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Curriculum Development&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Accessing and synthesizing educational standards&lt;/li&gt;
&lt;li&gt;Retrieving relevant teaching materials&lt;/li&gt;
&lt;li&gt;Creating comprehensive learning pathways&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;7-rag-implementation-challenges-and-solutions&#34;&gt;7. RAG Implementation Challenges and Solutions&lt;/h2&gt;
&lt;h3 id=&#34;retrieval-quality-optimization&#34;&gt;Retrieval Quality Optimization&lt;/h3&gt;
&lt;p&gt;Retrieval errors represent one of the most significant challenges in RAG systems:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Common Retrieval Issues&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semantic mismatch between query and relevant documents&lt;/li&gt;
&lt;li&gt;Over-reliance on lexical overlap&lt;/li&gt;
&lt;li&gt;Difficulty with implicit knowledge needs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Solutions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advanced query rewriting techniques&lt;/li&gt;
&lt;li&gt;Ensemble retrieval approaches&lt;/li&gt;
&lt;li&gt;Domain-specific embedding fine-tuning&lt;/li&gt;
&lt;li&gt;Continuous retrieval feedback loops&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hallucination-mitigation&#34;&gt;Hallucination Mitigation&lt;/h3&gt;
&lt;p&gt;Even with retrieval augmentation, LLMs can still produce inaccurate information:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Types of Hallucinations&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intrinsic: Originating from the model&amp;rsquo;s parametric knowledge&lt;/li&gt;
&lt;li&gt;Extrinsic: Misinterpreting or misrepresenting retrieved information&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mitigation Strategies&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explicit attribution requirements&lt;/li&gt;
&lt;li&gt;Confidence scoring and uncertainty indication&lt;/li&gt;
&lt;li&gt;Retrieval verification loops&lt;/li&gt;
&lt;li&gt;Fact-checking against retrieved information&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-latency-and-performance&#34;&gt;System Latency and Performance&lt;/h3&gt;
&lt;p&gt;RAG systems introduce additional computational steps that can impact response time:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance Bottlenecks&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Embedding generation time&lt;/li&gt;
&lt;li&gt;Vector search latency&lt;/li&gt;
&lt;li&gt;Context processing in large LLMs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Optimization Approaches&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Embedding caching and precomputation&lt;/li&gt;
&lt;li&gt;Vector database query optimization&lt;/li&gt;
&lt;li&gt;Tiered retrieval architectures&lt;/li&gt;
&lt;li&gt;Asynchronous prefetching strategies&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;8-future-directions-in-rag&#34;&gt;8. Future Directions in RAG&lt;/h2&gt;
&lt;h3 id=&#34;multimodal-rag-systems&#34;&gt;Multimodal RAG Systems&lt;/h3&gt;
&lt;p&gt;The evolution of RAG is moving beyond text to incorporate diverse data types:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Image-Text Retrieval&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Finding relevant images based on textual queries&lt;/li&gt;
&lt;li&gt;Retrieving text information based on image content&lt;/li&gt;
&lt;li&gt;Multimodal knowledge bases with mixed content types&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Audio and Video Integration&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Retrieving information from speech, music, or sound effects&lt;/li&gt;
&lt;li&gt;Accessing knowledge from video content&lt;/li&gt;
&lt;li&gt;Cross-modal retrieval across diverse media types&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;self-improving-rag&#34;&gt;Self-Improving RAG&lt;/h3&gt;
&lt;p&gt;Future RAG systems will continuously enhance their own performance:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Automatic Knowledge Base Refinement&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identifying knowledge gaps from user interactions&lt;/li&gt;
&lt;li&gt;Prioritizing areas for knowledge expansion&lt;/li&gt;
&lt;li&gt;Automatically curating and updating information&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Retrieval Strategy Optimization&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Learning optimal retrieval parameters from user feedback&lt;/li&gt;
&lt;li&gt;Adapting to different query types and domains&lt;/li&gt;
&lt;li&gt;Self-tuning for improved performance over time&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;agent-based-rag-architectures&#34;&gt;Agent-Based RAG Architectures&lt;/h3&gt;
&lt;p&gt;RAG is evolving from a passive information system to an active reasoning framework:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tool-Augmented RAG&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Combining retrieval with external tool usage&lt;/li&gt;
&lt;li&gt;Dynamic information gathering based on initial retrievals&lt;/li&gt;
&lt;li&gt;Closed-loop verification with external systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Multi-Agent RAG Systems&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Specialized retrievers for different knowledge domains&lt;/li&gt;
&lt;li&gt;Collaborative information synthesis across agents&lt;/li&gt;
&lt;li&gt;Hierarchical decision-making for complex queries&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;&lt;img src=&#34;https://cagatayturkan.com/blog/blog/en/rag-building-next-gen-ai-systems/images/multiAgentRagDiagram.svg&#34;
    alt=&#34;Conceptual diagram of multi-agent RAG architecture&#34;&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Retrieval Augmented Generation represents a fundamental shift in how we build AI systems that interact with information. By combining the creative and reasoning capabilities of large language models with the precision and timeliness of information retrieval, RAG creates AI systems that are more accurate, trustworthy, and useful.&lt;/p&gt;
&lt;p&gt;The key advantages of RAG include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Enhanced factual accuracy through external knowledge grounding&lt;/li&gt;
&lt;li&gt;Ability to access up-to-date information beyond the model&amp;rsquo;s training cutoff&lt;/li&gt;
&lt;li&gt;Domain adaptation without full model fine-tuning&lt;/li&gt;
&lt;li&gt;Transparent sourcing of information&lt;/li&gt;
&lt;li&gt;Reduced hallucination rates&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As RAG technologies continue to evolve, we can expect these systems to become even more sophisticated—incorporating multimodal data, engaging in more complex reasoning chains, and continuously improving their own performance. The future of AI lies not just in bigger models, but in smarter architectures that effectively combine neural and symbolic approaches to knowledge.&lt;/p&gt;
&lt;p&gt;Organizations implementing RAG today are already seeing significant benefits in knowledge management, customer support, research, and many other domains. As these techniques become more accessible and refined, they will form the foundation of a new generation of AI systems that are not just impressive in their language capabilities, but reliable in their knowledge.&lt;/p&gt;
&lt;hr&gt;
</content:encoded>
    </item>
    
    <item>
      <title>Modern AI Technologies and Node.js Integration</title>
      <link>https://cagatayturkan.com/blog/en/modern-ai-technologies-nodejs-integrations/</link>
      <pubDate>Sat, 01 Mar 2025 10:00:00 +0300</pubDate>
      
      <guid>https://cagatayturkan.com/blog/en/modern-ai-technologies-nodejs-integrations/</guid>
      <description>In this article, we will explore the applications of artificial intelligence technologies in the JavaScript ecosystem. We will discuss how fundamental concepts such as AI agents, tool calling, conversation memory, and context management can be implemented in Node.js applications through example projects.</description>
      
      <cardimage>https://cagatayturkan.com/blog/en/modern-ai-technologies-nodejs-integrations/images/cover.svg</cardimage>
      
      
      <featureimage>https://cagatayturkan.com/blog/en/modern-ai-technologies-nodejs-integrations/images/cover.svg</featureimage>
      
      <content:encoded>&lt;h1 id=&#34;modern-ai-technologies-and-nodejs-integration&#34;&gt;Modern AI Technologies and Node.js Integration&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Artificial intelligence technologies, especially language models, are rapidly transforming the software development world. Integrating AI technologies with a popular platform like Node.js offers incredible opportunities for developers working in the JavaScript ecosystem. In this article, we&amp;rsquo;ll explore how to implement modern AI concepts within the Node.js framework.&lt;/p&gt;
&lt;p&gt;This article will help you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understand AI terminology and fundamental concepts&lt;/li&gt;
&lt;li&gt;Integrate LLM (Large Language Model) with Node.js&lt;/li&gt;
&lt;li&gt;Understand creating AI agents and tool calling capabilities&lt;/li&gt;
&lt;li&gt;Use open-source AI technologies (Ollama, LiteLLM, LlamaCPP) in Node.js applications&lt;/li&gt;
&lt;li&gt;AI integration with N8n for automated workflows&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can access the complete code for the projects at &lt;a href=&#34;https://github.com/cagatayturkann/blogProjects/tree/main/nodejs-ai-examples&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;1-ai-agents-developing-intelligent-assistants&#34;&gt;1. AI Agents: Developing Intelligent Assistants&lt;/h2&gt;
&lt;h3 id=&#34;what-is-an-ai-agent&#34;&gt;What is an AI Agent?&lt;/h3&gt;
&lt;p&gt;AI agents are software systems designed to perform specific tasks using LLMs (Large Language Models). These agents possess human-like thinking, decision-making, and interaction capabilities. An AI agent is an autonomous software component designed to perform specific tasks. These agents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Receive input: For example, queries from users or data from systems.&lt;/li&gt;
&lt;li&gt;Process: Analyze this data, make decisions, or run models.&lt;/li&gt;
&lt;li&gt;Provide output: Execute results or actions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Modern AI agents typically include these components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;LLM (Brain)&lt;/strong&gt;: Natural language understanding and generation capability&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Ability to remember past interactions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Ability to interact with APIs, databases, and other systems&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Planning&lt;/strong&gt;: Ability to break complex tasks into subtasks&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;AI Agents can be reactive, meaning they don&amp;rsquo;t collect data, analyze environment, etc. without any user trigger, or they can be autonomous, which is more common. An autonomous agent, for example in a smart home system, can continuously monitor the environment, detect specific conditions, and make its own decisions. Such an agent continuously collects data from sources like sensors, analyzes this data, and independently initiates or adjusts certain tasks based on this analysis.&lt;/p&gt;
&lt;h3 id=&#34;creating-an-ai-agent-with-nodejs&#34;&gt;Creating an AI Agent with Node.js&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s create a simple autonomous agent example using Node.js and OpenAI API. In this example, the agent generates &amp;ldquo;sensor data&amp;rdquo; at specific intervals and acts according to the decision it receives from OpenAI. First, let&amp;rsquo;s install the required package.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;npm install openai
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then our code is as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;OpenAI&lt;/span&gt; } &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;openai&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// OpenAI configuration: Add your API key here
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;openai&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;OpenAI&lt;/span&gt;({
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;apiKey&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;your-api-key&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;});
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Autonomous agent function
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;autonomousAgent&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Agent started working...&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// Step 1: Simulate sensor data (e.g., a random number)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sensorData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Math.&lt;span style=&#34;color:#a6e22e&#34;&gt;random&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sensor data:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;sensorData&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// Step 2: Send prompt to OpenAI for decision based on sensor data
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`Sensor data: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sensorData&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;. Return a single word &amp;#34;Alarm&amp;#34; if the value is greater than 50, or &amp;#34;Normal&amp;#34; if it&amp;#39;s 50 or less.`&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;openai&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;chat&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;completions&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;create&lt;/span&gt;({
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gpt-4o-mini&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; [{ &lt;span style=&#34;color:#a6e22e&#34;&gt;role&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; }],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;max_tokens&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;temperature&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;decision&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;choices&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;].&lt;span style=&#34;color:#a6e22e&#34;&gt;message&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;trim&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Agent Decision:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;decision&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Step 3: Take action based on OpenAI&amp;#39;s decision
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;decision&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;===&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Alarm&amp;#39;&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Alarm condition detected, initiating necessary actions...&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#75715e&#34;&gt;// Here you can add actions like triggering alarms or sending notifications
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    } &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;decision&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;===&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Normal&amp;#39;&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Situation normal, in standby mode...&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#75715e&#34;&gt;// Additional actions for normal state can be added here
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    } &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Unknown decision, rechecking...&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#75715e&#34;&gt;// Error handling for unexpected situations
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Error occurred:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Run the agent automatically every 30 seconds
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;setInterval&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;autonomousAgent&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Run the program once immediately when it starts
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;autonomousAgent&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s explain this code in more detail:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Sensor Data Generation:&lt;/strong&gt; The agent generates a random number each time it runs. This number is considered as sample sensor data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decision Process:&lt;/strong&gt; The generated sensor data is sent to OpenAI API within a prompt. This prompt asks to return either &amp;ldquo;Alarm&amp;rdquo; or &amp;ldquo;Normal&amp;rdquo; based on the data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action:&lt;/strong&gt; The response from OpenAI determines the agent&amp;rsquo;s decision. If the response is &amp;ldquo;Alarm&amp;rdquo;, the agent performs actions that trigger the alarm state; if &amp;ldquo;Normal&amp;rdquo;, it remains in standby mode.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autonomy:&lt;/strong&gt; The agent works independently at regular intervals (here every 30 seconds) without user intervention, evaluating sensor data and making decisions automatically.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This example demonstrates the concept of an autonomous agent as a structure that is not dependent solely on user input, self-triggering, and making decisions based on specific conditions. Thus, the system can take action based on environmental data while working independently in a specific time cycle.&lt;/p&gt;
&lt;h3 id=&#34;ai-agent-working-principle&#34;&gt;AI Agent Working Principle&lt;/h3&gt;
&lt;p&gt;AI agents typically follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Thinking&lt;/strong&gt;: Creating a plan for the requested task&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tool Selection&lt;/strong&gt;: Deciding which tool to use to complete the task&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action&lt;/strong&gt;: Performing a specific action using the selected tool&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Observation&lt;/strong&gt;: Examining the result of the action&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Progress&lt;/strong&gt;: Starting a new thinking-action cycle based on the result&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This approach is known as ReAct (Reasoning and Acting) and enables LLM to combine thinking with action.&lt;/p&gt;
&lt;h3 id=&#34;why-is-this-feature-important&#34;&gt;Why is This Feature Important?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You can delegate automatable operations to intelligent assistants&lt;/li&gt;
&lt;li&gt;You can provide a more natural interface to human users&lt;/li&gt;
&lt;li&gt;You can simplify complex workflows with modular tools&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-embedding-rag-vectordb&#34;&gt;2. Embedding, RAG, VectorDB&lt;/h2&gt;
&lt;h3 id=&#34;embedding&#34;&gt;Embedding&lt;/h3&gt;
&lt;p&gt;Embedding is the process of converting text or other data types into numerical vectors. These vectors represent the semantic features of the data in numerical format. For example, the words &amp;ldquo;dog&amp;rdquo; and &amp;ldquo;cat&amp;rdquo; are represented by vectors close to each other, while &amp;ldquo;car&amp;rdquo; is represented by a more distant vector.&lt;/p&gt;
&lt;p&gt;Embeddings are used for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Calculating text similarity&lt;/li&gt;
&lt;li&gt;Document classification&lt;/li&gt;
&lt;li&gt;Semantic search&lt;/li&gt;
&lt;li&gt;Creating recommendations&lt;/li&gt;
&lt;li&gt;Sentiment analysis&lt;/li&gt;
&lt;li&gt;Text summarization&lt;/li&gt;
&lt;li&gt;Natural language processing tasks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The working principle of embeddings is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tokenization&lt;/strong&gt;: Text is first divided into smaller pieces (tokens)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector Transformation&lt;/strong&gt;: Each token is converted into a vector of hundreds or thousands of dimensions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Normalization&lt;/strong&gt;: Vectors are normalized to make them comparable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The most important feature of embeddings is that content with similar meanings is positioned close to each other in vector space. This allows for meaning-based results in text-based searches rather than word matching. For example, the words &amp;ldquo;happy&amp;rdquo; and &amp;ldquo;joyful&amp;rdquo; are positioned close to each other in vector space, while the word &amp;ldquo;sad&amp;rdquo; is located at a distant point.&lt;/p&gt;
&lt;h3 id=&#34;rag-retrieval-augmented-generation&#34;&gt;RAG (Retrieval Augmented Generation)&lt;/h3&gt;
&lt;p&gt;RAG is a technique that enriches the existing knowledge base of large language models (LLM) with external sources. The RAG system works as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Retrieval&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Documents or information related to the user question are retrieved from the database&lt;/li&gt;
&lt;li&gt;Most relevant content is found using semantic search&lt;/li&gt;
&lt;li&gt;Documents are ranked by embedding similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Augmentation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Found information is added to the prompt sent to LLM&lt;/li&gt;
&lt;li&gt;Information is arranged by order of importance&lt;/li&gt;
&lt;li&gt;Context window is optimized&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Generation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM generates response using enriched context&lt;/li&gt;
&lt;li&gt;Response can reference given sources&lt;/li&gt;
&lt;li&gt;Reliability score can be calculated&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Advantages of RAG:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use of current information&lt;/li&gt;
&lt;li&gt;Increased accuracy&lt;/li&gt;
&lt;li&gt;Customized responses&lt;/li&gt;
&lt;li&gt;Reduced hallucinations&lt;/li&gt;
&lt;li&gt;Traceability of sources&lt;/li&gt;
&lt;li&gt;Dynamic information update capability&lt;/li&gt;
&lt;li&gt;Domain-specific knowledge integration&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vector-db&#34;&gt;Vector DB&lt;/h3&gt;
&lt;p&gt;Vector databases are specialized database systems for storing embedding vectors and performing similarity searches on these vectors. Unlike traditional databases, they can quickly calculate similarity between vectors.&lt;/p&gt;
&lt;p&gt;Vector DB Core Features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Efficient storage of high-dimensional vectors&lt;/li&gt;
&lt;li&gt;Similarity-based search (cosine similarity, euclidean distance)&lt;/li&gt;
&lt;li&gt;Fast nearest neighbor queries&lt;/li&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;CRUD operations&lt;/li&gt;
&lt;li&gt;Metadata filtering&lt;/li&gt;
&lt;li&gt;Batch processing support&lt;/li&gt;
&lt;li&gt;Vector indexing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Vector DBs are particularly used in these areas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semantic document search&lt;/li&gt;
&lt;li&gt;Recommendation systems&lt;/li&gt;
&lt;li&gt;Image and audio similarity analysis&lt;/li&gt;
&lt;li&gt;Natural language processing applications&lt;/li&gt;
&lt;li&gt;Face recognition systems&lt;/li&gt;
&lt;li&gt;Anomaly detection&lt;/li&gt;
&lt;li&gt;Cross-modal search (text-to-image, image-to-text)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Popular Vector DB solutions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pinecone: Fully managed, scalable solution&lt;/li&gt;
&lt;li&gt;Weaviate: Open source, self-hosted option&lt;/li&gt;
&lt;li&gt;Milvus: High-performance, distributed architecture&lt;/li&gt;
&lt;li&gt;Qdrant: Rust-based, fast and lightweight&lt;/li&gt;
&lt;li&gt;ChromaDB: Python-focused, ideal for getting started&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-tool-calling-adding-new-capabilities-to-ai&#34;&gt;3. Tool Calling: Adding New Capabilities to AI&lt;/h2&gt;
&lt;h3 id=&#34;what-is-tool-calling&#34;&gt;What is Tool Calling?&lt;/h3&gt;
&lt;p&gt;Tool calling is the ability of an AI model to call external functions or APIs. This allows AI to perform operations beyond its knowledge boundaries.&lt;/p&gt;
&lt;p&gt;Modern LLMs have the ability to make tool calls in JSON format. This allows the model to define the action it wants to perform and the necessary parameters.&lt;/p&gt;
&lt;h3 id=&#34;tool-calling-with-nodejs&#34;&gt;Tool Calling with Node.js&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s implement tool calling using the OpenAI API. In the example below, we&amp;rsquo;re creating an agent that demonstrates the concept of &amp;ldquo;tool calling&amp;rdquo; using Node.js. This agent calls two different &amp;ldquo;tools&amp;rdquo;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Weather API (OpenWeatherMap):&lt;/strong&gt; The agent retrieves current weather data for a specific location.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenAI API:&lt;/strong&gt; Using the weather data it receives, it requests a brief analysis of how the day is going.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By using these two tools sequentially, we can see how the agent collects data from external sources and processes this data.&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s install the required libraries&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;npm install axios openai
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Örnek kodumuz ise aşağıdaki şekilde.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;axios&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;axios&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;OpenAI&lt;/span&gt; } &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;openai&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Enter your API keys
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;WEATHER_API_KEY&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;your-api-key&amp;gt;&amp;#39;&lt;/span&gt;; &lt;span style=&#34;color:#75715e&#34;&gt;// Your OpenWeatherMap API key
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Location to query weather for
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;LOCATION&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Istanbul&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// OpenAI configuration
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;openai&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;OpenAI&lt;/span&gt;({
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;apiKey&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;your-api-key&amp;gt;&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;});
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Step 1: Function to call Weather API
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getWeatherData&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;location&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;axios&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;get&lt;/span&gt;(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#e6db74&#34;&gt;`https://api.openweathermap.org/data/2.5/weather?q=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;amp;appid=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;WEATHER_API_KEY&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;amp;units=metric`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;data&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Weather API error:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Step 2: Function to send data to OpenAI API and get analysis
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;analyzeWeather&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Could not retrieve weather data.&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// Create prompt based on weather data
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`Currently in &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, the weather is &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;weather&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;].&lt;span style=&#34;color:#a6e22e&#34;&gt;description&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; and temperature is &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;temp&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;°C. Based on this weather, how is the day going and what kind of activity would you recommend? Give a brief summary.`&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;openai&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;chat&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;completions&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;create&lt;/span&gt;({
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gpt-4o-mini&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; [{ &lt;span style=&#34;color:#a6e22e&#34;&gt;role&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; }],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;max_tokens&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;60&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;temperature&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;choices&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;].&lt;span style=&#34;color:#a6e22e&#34;&gt;message&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;trim&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;OpenAI API error:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Weather analysis failed.&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Main function: Calls tools in sequence
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Starting Tool Calling Agent...&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// Call tool to get weather data
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getWeatherData&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;LOCATION&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Received Weather Data:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// Send data to OpenAI API and get analysis
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;analysis&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;analyzeWeather&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;weatherData&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Analysis Result:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;analysis&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Bu örnekte, agent &amp;ldquo;tool calling&amp;rdquo; yaparak iki farklı dış kaynağı (OpenWeatherMap ve OpenAI) kullanıyor. Öncelikle hava durumu verisi toplanıyor; ardından bu veri, bir analiz için OpenAI API&amp;rsquo;sine gönderiliyor. Böylece, ajanın kendi yeteneklerinin ötesinde dış kaynaklardan faydalanması sağlanıyor.&lt;/p&gt;
&lt;h3 id=&#34;farklı-araç-türleri&#34;&gt;Farklı Araç Türleri&lt;/h3&gt;
&lt;p&gt;AI sistemlerinize entegre edebileceğiniz bazı araç türleri:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Veritabanı İşlemleri&lt;/strong&gt;: Veri sorgulama, ekleme, güncelleme&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API Çağrıları&lt;/strong&gt;: Harici servislere bağlanma (hava durumu, borsa, haberler)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dosya İşlemleri&lt;/strong&gt;: Dosya okuma, yazma, dönüştürme&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hesaplamalar&lt;/strong&gt;: Karmaşık matematiksel işlemler&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Takvim/Zamanlama&lt;/strong&gt;: Etkinlik oluşturma, hatırlatıcı ayarlama&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;tool-calling-best-practices&#34;&gt;Tool Calling Best Practices&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Açık Tanımlamalar&lt;/strong&gt;: Araçlarınızı açık ve net tanımlayın, parametreleri dokumentasyon içerisinde detaylandırın&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Güvenlik Kontrolleri&lt;/strong&gt;: Kullanıcı girdilerini doğrulayın&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Graceful Failure&lt;/strong&gt;: Araçlar hata verdiğinde zarif bir şekilde geri dönüş yapın&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Aşamalı Geliştirme&lt;/strong&gt;: Önce basit araçlarla başlayın, sonra karmaşıklığı artırın&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;4-conversation-memory-adding-memory-to-ai&#34;&gt;4. Conversation Memory: Adding Memory to AI&lt;/h2&gt;
&lt;h3 id=&#34;what-is-conversation-memory&#34;&gt;What is Conversation Memory?&lt;/h3&gt;
&lt;p&gt;Conversation memory is the ability of an AI system to remember previous interactions and respond accordingly. This feature ensures that the conversation is consistent and contextual.&lt;/p&gt;
&lt;h3 id=&#34;why-is-it-important&#34;&gt;Why is it Important?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Provides contextual consistency. Users don&amp;rsquo;t need to provide context every time. That is, during dialogue, the agent &amp;lsquo;remembers&amp;rsquo; previous messages. Thus, information given at the beginning of a conversation ensures that subsequent responses are more meaningful and consistent.&lt;/li&gt;
&lt;li&gt;AI can reference previous requests&lt;/li&gt;
&lt;li&gt;Provides more natural and human-like interactions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s an example usage of conversation memory. A chatbot keeps the user&amp;rsquo;s name, areas of interest, or previously asked questions in its memory and references this information in subsequent responses. Thus, each message becomes connected and the conversation gains a natural flow. This memory is usually implemented by storing a certain portion of previous messages. Language models use this historical information as input to produce responses with a better understanding of context. Effective use of conversation memory brings challenges such as memory size and maintaining information currency in long dialogues. As a result, conversation memory is a critical component for AI Agents to produce more &amp;lsquo;intelligent&amp;rsquo; and contextual responses. This feature allows for long and meaningful conversations.&lt;/p&gt;
&lt;h3 id=&#34;conversation-memory-with-nodejs&#34;&gt;Conversation Memory with Node.js&lt;/h3&gt;
&lt;p&gt;Below is an example of a chatbot that maintains conversation memory. In this example, each user&amp;rsquo;s chat history is stored in MongoDB and we send the history as a prompt to OpenAI when a new message arrives.&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s install the required libraries:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;npm install mongodb express openai
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here&amp;rsquo;s our example code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;express&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;express&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;MongoClient&lt;/span&gt; } &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mongodb&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;OpenAI&lt;/span&gt; } &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;openai&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;app&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;express&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;app&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;use&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;express&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;json&lt;/span&gt;());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;OPENAI_API_KEY&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;your-api-key&amp;gt;&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;MONGO_URI&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mongodb://localhost:27017&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;DATABASE_NAME&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;conversationDB&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;COLLECTION_NAME&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;conversations&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// OpenAI configuration
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;openai&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;OpenAI&lt;/span&gt;({
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;apiKey&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;OPENAI_API_KEY&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;});
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// MongoDB connection
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;client&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;MongoClient&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;MONGO_URI&lt;/span&gt;, { &lt;span style=&#34;color:#a6e22e&#34;&gt;useUnifiedTopology&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conversationCollection&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;client&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  .&lt;span style=&#34;color:#a6e22e&#34;&gt;connect&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  .&lt;span style=&#34;color:#a6e22e&#34;&gt;then&lt;/span&gt;(() =&amp;gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;db&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;client&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;db&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;DATABASE_NAME&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;conversationCollection&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;db&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;collection&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;COLLECTION_NAME&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Connected to MongoDB.&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  })
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  .&lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt;((&lt;span style=&#34;color:#a6e22e&#34;&gt;err&lt;/span&gt;) =&amp;gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MongoDB connection error:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;err&lt;/span&gt;));
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Chat endpoint
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;app&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;post&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/chat&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;req&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;res&lt;/span&gt;) =&amp;gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;userId&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;message&lt;/span&gt; } &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;req&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;body&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;userId&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;message&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;res&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;status&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;).&lt;span style=&#34;color:#a6e22e&#34;&gt;send&lt;/span&gt;({ &lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;userId and message are required.&amp;#39;&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Get user&amp;#39;s previous chat history
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conversation&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conversationCollection&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;findOne&lt;/span&gt;({ &lt;span style=&#34;color:#a6e22e&#34;&gt;userId&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;conversation&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;conversation&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;userId&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; [] };
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Add user message to history
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;conversation&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;push&lt;/span&gt;({ &lt;span style=&#34;color:#a6e22e&#34;&gt;role&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;message&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Convert conversation history to prompt
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;conversation&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;forEach&lt;/span&gt;((&lt;span style=&#34;color:#a6e22e&#34;&gt;msg&lt;/span&gt;) =&amp;gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;msg&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;role&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;===&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;User&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Agent&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;msg&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;\n`&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Agent:&amp;#39;&lt;/span&gt;; &lt;span style=&#34;color:#75715e&#34;&gt;// For agent&amp;#39;s response
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// OpenAI API call
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;openai&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;chat&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;completions&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;create&lt;/span&gt;({
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gpt-4o-mini&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; [{ &lt;span style=&#34;color:#a6e22e&#34;&gt;role&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prompt&lt;/span&gt; }],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;max_tokens&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#a6e22e&#34;&gt;temperature&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agentReply&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;response&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;choices&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;].&lt;span style=&#34;color:#a6e22e&#34;&gt;message&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;trim&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Add agent response to history
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;conversation&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;push&lt;/span&gt;({ &lt;span style=&#34;color:#a6e22e&#34;&gt;role&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;agent&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;content&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agentReply&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Save updated conversation to MongoDB (upsert)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conversationCollection&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;updateOne&lt;/span&gt;({ &lt;span style=&#34;color:#a6e22e&#34;&gt;userId&lt;/span&gt; }, { &lt;span style=&#34;color:#a6e22e&#34;&gt;$set&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conversation&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;messages&lt;/span&gt; } }, { &lt;span style=&#34;color:#a6e22e&#34;&gt;upsert&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;res&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;send&lt;/span&gt;({ &lt;span style=&#34;color:#a6e22e&#34;&gt;reply&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agentReply&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Error processing chat:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;res&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;status&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;).&lt;span style=&#34;color:#a6e22e&#34;&gt;send&lt;/span&gt;({ &lt;span style=&#34;color:#a6e22e&#34;&gt;error&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Server error&amp;#39;&lt;/span&gt; });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;});
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;app&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;listen&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3000&lt;/span&gt;, () =&amp;gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;console&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Server running on port 3000.&amp;#39;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;});
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Example cURL request:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl --location &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://localhost:3000/chat&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--header &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Content-Type: application/json&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--data &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;userId&amp;#34;: &amp;#34;123&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;message&amp;#34;: &amp;#34;what&amp;#39;&lt;/span&gt;s the temperature in Istanbul&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here&amp;rsquo;s how an example scenario might develop:
User =&amp;gt; What&amp;rsquo;s the temperature in Istanbul today?
Agent =&amp;gt; It&amp;rsquo;s 23 degrees and sunny in Istanbul
User =&amp;gt; What about Izmir?
Agent =&amp;gt; It&amp;rsquo;s 26 degrees and sunny in Izmir.&lt;/p&gt;
&lt;p&gt;The agent maintains history here, so in the second question, even though words like &amp;rsquo;temperature&amp;rsquo; or &amp;lsquo;weather&amp;rsquo; aren&amp;rsquo;t mentioned, just from the &amp;ldquo;what about Izmir?&amp;rdquo; query, it knows to provide weather information because it maintains the conversation history.&lt;/p&gt;
&lt;h2 id=&#34;5-model-context-protocol-managing-llm-context&#34;&gt;5. Model Context Protocol: Managing LLM Context&lt;/h2&gt;
&lt;p&gt;Model Context Protocol (MCP) refers to specific rules and configurations about what information should be provided to a language model (e.g., GPT-4, Claude 3.7 Sonnet), in what format, and how. Let&amp;rsquo;s explore the following topics to better understand this concept.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Defining and Formatting Context&lt;/strong&gt;
What is Context =&amp;gt; Language models rely solely on the input (prompt) sent to them when generating responses. This input can include various elements such as conversation history, system instructions, user questions, and even data obtained from tool calls.
What is Protocol =&amp;gt; The term protocol refers to the rules that determine how this information will be organized, ordered, and formatted. For example, OpenAI&amp;rsquo;s ChatGPT model separates chat history with &amp;lsquo;system&amp;rsquo;, &amp;lsquo;user&amp;rsquo;, and &amp;lsquo;assistant&amp;rsquo; roles. This structure determines which information the model will prioritize.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Conversation Memory and Context Management&lt;/strong&gt;
Conversation Memory =&amp;gt; Conversation memory is a mechanism that enables remembering previous messages. However, the model doesn&amp;rsquo;t directly store state; context is provided by adding previous messages to the prompt each time.
Token Limit =&amp;gt; Models have a limit on the total number of tokens they can process. Therefore, decisions such as which past messages to include and which information to summarize are handled within the scope of &amp;ldquo;model context protocol&amp;rdquo;. This ensures the model sees the most relevant information.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic and Static Information&lt;/strong&gt;
Dynamic Information =&amp;gt; Information that is continuously updated during conversation (e.g., user messages, responses from tools) is added to the prompt as part of dynamic context.
Static Information =&amp;gt; There may also be some system instructions, fixed commands, or information that specify how the model should behave. For example, requesting the model to respond in a specific tone or language.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Application Example&lt;/strong&gt;
Let&amp;rsquo;s say we&amp;rsquo;re creating a chatbot. MCP in this chatbot project could work with this logic:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;System Message =&amp;gt;&lt;/strong&gt; &amp;ldquo;This is a customer support chat. Provide your answers in a polite and helpful tone.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User Messages =&amp;gt;&lt;/strong&gt; Past messages like &amp;ldquo;Hello, I have an issue with my account&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tool Calls =&amp;gt;&lt;/strong&gt; If data is being retrieved from external APIs, this data is also included in the prompt appropriately&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prompt Creation =&amp;gt;&lt;/strong&gt; All this information is combined in a specific order and format (e.g., User: &amp;hellip;, Agent: &amp;hellip;) and sent to the model to generate a response.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, MCP serves as a guide that determines what information will be given to the language model, how this information will be structured, and how the model will produce more effective responses. Creating a proper protocol helps the model better understand context and provide more consistent, relevant answers. This concept is particularly critical in long and complex dialogues for keeping the right information within the model&amp;rsquo;s comprehensible limits.&lt;/p&gt;
&lt;h2 id=&#34;6-fine-tuning-customizing-llms&#34;&gt;6. Fine-tuning: Customizing LLMs&lt;/h2&gt;
&lt;p&gt;Fine-tuning is the process of customizing a pre-trained language model (LLM) for a specific task or domain. This process ensures that the model produces more accurate and consistent responses for a particular use case.&lt;/p&gt;
&lt;h3 id=&#34;when-to-use-fine-tuning&#34;&gt;When to Use Fine-tuning?&lt;/h3&gt;
&lt;p&gt;Fine-tuning is particularly useful in these situations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tasks requiring specific domain knowledge&lt;/li&gt;
&lt;li&gt;Outputs requiring consistent format or style&lt;/li&gt;
&lt;li&gt;Situations requiring brand voice and tone alignment&lt;/li&gt;
&lt;li&gt;Technical terminology usage&lt;/li&gt;
&lt;li&gt;Multiple similar task repetitions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fine-tuning-advantages&#34;&gt;Fine-tuning Advantages&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Better Performance&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More accurate answers in domain-specific tasks&lt;/li&gt;
&lt;li&gt;More consistent output format&lt;/li&gt;
&lt;li&gt;Reduced hallucinations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost Optimization&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ability to use shorter prompts&lt;/li&gt;
&lt;li&gt;Less token consumption&lt;/li&gt;
&lt;li&gt;Faster response times&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Customized Behavior&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Responses aligned with brand language&lt;/li&gt;
&lt;li&gt;Consistent tone and style&lt;/li&gt;
&lt;li&gt;Ability to learn specific rules&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;fine-tuning-process&#34;&gt;Fine-tuning Process&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Preparation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collecting training data&lt;/li&gt;
&lt;li&gt;Data cleaning and formatting&lt;/li&gt;
&lt;li&gt;Creating prompt-completion pairs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Determining base model&lt;/li&gt;
&lt;li&gt;Adjusting model parameters&lt;/li&gt;
&lt;li&gt;Selecting training strategy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hyperparameter optimization&lt;/li&gt;
&lt;li&gt;Monitoring training metrics&lt;/li&gt;
&lt;li&gt;Cross-validation checks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model performance analysis&lt;/li&gt;
&lt;li&gt;A/B tests&lt;/li&gt;
&lt;li&gt;Human evaluation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;fine-tuning-best-practices&#34;&gt;Fine-tuning Best Practices&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Quality&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use high-quality training data&lt;/li&gt;
&lt;li&gt;Ensure data diversity&lt;/li&gt;
&lt;li&gt;Create balanced data distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose appropriate model size for task&lt;/li&gt;
&lt;li&gt;Consider cost-performance balance&lt;/li&gt;
&lt;li&gt;Evaluate base model performance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Training Strategy&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apply gradual fine-tuning&lt;/li&gt;
&lt;li&gt;Prevent overfitting&lt;/li&gt;
&lt;li&gt;Conduct regular evaluation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deployment&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implement model versioning&lt;/li&gt;
&lt;li&gt;Set up performance monitoring mechanisms&lt;/li&gt;
&lt;li&gt;Create feedback loop&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;7-ollama-litellm-llamacpp-open-source-ai-solutions&#34;&gt;7. Ollama, LiteLLM, LlamaCPP: Open Source AI Solutions&lt;/h2&gt;
&lt;p&gt;Open-source LLMs and tools make AI development processes more accessible. In this section, we&amp;rsquo;ll explore popular open-source AI solutions you can use in your Node.js applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ollama:&lt;/strong&gt; Ollama is a platform that allows users to run large language models (e.g., LLaMA, GPT derivatives) on their own machines, typically providing a user-friendly interface. Such applications are designed to facilitate model installation, updates, and integration; thus, enabling secure and fast access locally without depending on internet connection.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LiteLLM:&lt;/strong&gt; Litellm is a library or tool developed with a &amp;ldquo;lightweight&amp;rdquo; approach to facilitate working with large language models. It typically offers minimal resource usage, flexibility, and rapid prototyping capabilities. Such tools focus on running existing large models with fewer resources rather than model training.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LlamaCpp:&lt;/strong&gt; LlamaCpp is a C++ optimized implementation of large language models like Meta&amp;rsquo;s LLaMA model. This library aims to efficiently run quantized models on CPU. Thus, it becomes possible to run LLM locally without needing powerful GPUs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;comparison-of-open-source-ai-solutions&#34;&gt;Comparison of Open Source AI Solutions&lt;/h3&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Feature&lt;/th&gt;
          &lt;th&gt;Ollama&lt;/th&gt;
          &lt;th&gt;LiteLLM&lt;/th&gt;
          &lt;th&gt;LlamaCPP&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Ease of Setup&lt;/td&gt;
          &lt;td&gt;★★★★★&lt;/td&gt;
          &lt;td&gt;★★★★☆&lt;/td&gt;
          &lt;td&gt;★★☆☆☆&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Performance&lt;/td&gt;
          &lt;td&gt;★★★★☆&lt;/td&gt;
          &lt;td&gt;★★★★☆&lt;/td&gt;
          &lt;td&gt;★★★★★&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;API Compatibility&lt;/td&gt;
          &lt;td&gt;★★★☆☆&lt;/td&gt;
          &lt;td&gt;★★★★★&lt;/td&gt;
          &lt;td&gt;★★☆☆☆&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Resource Usage&lt;/td&gt;
          &lt;td&gt;★★★☆☆&lt;/td&gt;
          &lt;td&gt;★★★★☆&lt;/td&gt;
          &lt;td&gt;★★★★★&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Multi-Model Support&lt;/td&gt;
          &lt;td&gt;★★★★☆&lt;/td&gt;
          &lt;td&gt;★★★★★&lt;/td&gt;
          &lt;td&gt;★★★☆☆&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Cost&lt;/td&gt;
          &lt;td&gt;Free&lt;/td&gt;
          &lt;td&gt;Free*&lt;/td&gt;
          &lt;td&gt;Free&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In summary, while they all aim to facilitate the use of large language models in local or optimized environments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ollama offers integrated solutions by simplifying usage as a more comprehensive platform,&lt;/li&gt;
&lt;li&gt;Litellm aims to provide flexibility to developers with its lightweight and modular structure,&lt;/li&gt;
&lt;li&gt;LlamaCpp offers a C++ optimized solution particularly in terms of performance and low resource usage.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These tools can be preferred based on the hardware and usage scenario they will be run on. For example, litellm can be used for rapid prototyping in your development environment, while llamaCpp might be preferred for performance-focused local applications; Ollama can appeal to those seeking a more comprehensive user experience.&lt;/p&gt;
&lt;h2 id=&#34;8-n8n-ai-workflow-automation&#34;&gt;8. N8n: AI Workflow Automation&lt;/h2&gt;
&lt;p&gt;N8n is an open-source automation tool that allows you to automate workflows with no or minimal code. N8n&amp;rsquo;s flexible structure allows you to easily integrate AI services with other applications. N8n is completely open-source; this means you can access, customize, and adapt the source code according to your needs. Thanks to its drag-and-drop interface, you can design flows consisting of &amp;ldquo;nodes&amp;rdquo;, each performing a specific operation. This allows even users with little technical knowledge to create complex workflows.&lt;/p&gt;
&lt;p&gt;N8n provides integration with numerous APIs and services, allowing you to transfer data or perform automatic operations between different systems such as email, database, social media, file storage. You can host N8n on your own servers. This ensures complete control over your data and provides an advantage especially in privacy or compliance matters.&lt;/p&gt;
&lt;p&gt;For example, if you want to add a record to a database when receiving an email in a customer support process, then send a notification via Slack, you can arrange these steps visually with n8n and make them automatic.&lt;/p&gt;
&lt;h3 id=&#34;ai-workflows-possible-with-n8n&#34;&gt;AI Workflows Possible with N8n&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Document Processing and Summarization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatically summarizing email attachments&lt;/li&gt;
&lt;li&gt;Analyzing PDF documents and extracting data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Customer Support Automation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analyzing and classifying incoming customer questions&lt;/li&gt;
&lt;li&gt;Generating automatic responses to simple questions, routing complex ones&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Social Media Management&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatically generating content on specific topics&lt;/li&gt;
&lt;li&gt;Classifying and responding to comments with sentiment analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data Analysis and Reporting&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analyzing and summarizing periodic data&lt;/li&gt;
&lt;li&gt;Detecting data anomalies and sending alerts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;advantages-of-n8n-and-ai-integration&#34;&gt;Advantages of N8n and AI Integration&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Automation Without Code&lt;/strong&gt;: Even non-technical team members can create complex AI workflows&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-Service Integration&lt;/strong&gt;: You can incorporate AI into all your business processes with 200+ integrations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Self-Hosting&lt;/strong&gt;: You can run on your own infrastructure for AI operations containing sensitive data&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flexible Triggers&lt;/strong&gt;: You can initiate AI operations with timer, webhook, event-based triggers&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;final-words&#34;&gt;Final Words&lt;/h3&gt;
&lt;p&gt;AI technologies are rapidly evolving, and their integration in the Node.js ecosystem is becoming increasingly easier. The techniques we&amp;rsquo;ve seen in this article provide a solid foundation for developing AI-powered applications.&lt;/p&gt;
&lt;p&gt;You can develop more powerful and intelligent applications using modern AI technologies such as embeddings, RAG (Retrieval Augmented Generation), and vector databases, along with fundamental concepts like AI agents, tool calling, conversation memory, and context management. With fine-tuning, you can customize your models to achieve more successful results in domain-specific tasks.&lt;/p&gt;
&lt;p&gt;Together with open-source models and automation tools like N8n, you can develop solutions such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chatbots that produce more accurate and context-aware responses&lt;/li&gt;
&lt;li&gt;Intelligent document processing and analysis systems&lt;/li&gt;
&lt;li&gt;Semantic search and recommendation engines&lt;/li&gt;
&lt;li&gt;Automated workflows&lt;/li&gt;
&lt;li&gt;Domain-specific AI assistants&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can access all code examples shown in this article and more at &lt;a href=&#34;https://github.com/cagatayturkann/blogProjects/tree/main/nodejs-ai-examples&#34;&gt;GitHub Repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Good luck on your artificial intelligence journey!&lt;/p&gt;
&lt;hr&gt;
</content:encoded>
    </item>
    
  </channel>
</rss> 